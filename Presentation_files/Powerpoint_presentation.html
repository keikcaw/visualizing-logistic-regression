<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Visualizing logistic regression results for non-technical audiences</title>
    <meta charset="utf-8" />
    <meta name="author" content="Abby Kaplan and Keiko Cawley" />
    <meta name="date" content="2022-09-20" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Visualizing logistic regression results for non-technical audiences
]
.author[
### Abby Kaplan and Keiko Cawley
]
.date[
### September 20, 2022
]

---






&lt;style type="text/css"&gt;
.remark-code {
  font-size: 75% !important;
}
&lt;/style&gt;

class: inverse, center, middle

# Logistic regression review

---

# Logistic regression: Binary outcomes

- Use logistic regression to model a binary outcome

--

- Examples from higher education:

--

  - Did the student pass the class?

--

  - Did the student enroll for another term?

--

  - Did the student graduate?

---

# The design of logistic regression

- We want to model the probability that the outcome happened

--

- But probabilities are bounded between 0 and 1

--

- Instead, we model the logit of the probability:

$$
\mbox{logit}(p) = \log\left(\begin{array}{c}\frac{p}{1 - p}\end{array}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n
$$

---

class: inverse, center, middle

# What's the problem?

---

layout: true

# Just tell me "the" effect

- Stakeholders often want to know whether something affects outcomes, and by how much

---

--

- But we don't model probabilities directly

$$
\log\left(\begin{array}{c}\frac{p}{1 - p}\end{array}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n
$$

---

- But we don't model probabilities directly

$$
\boxed{\log\left(\begin{array}{c}\frac{p}{1 - p}\end{array}\right)} = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n
$$

--

- We can solve for _p_:

$$
`\begin{aligned}
p &amp; = \mbox{logit}^{-1}(\beta_0 + \beta_1x_1 + \ldots + \beta_nx_n) \\ &amp; \\
&amp; = \frac{e^{\beta_0 + \beta_1x_1 + \ldots + \beta_nx_n}}{1 + e^{\beta_0 + \beta_1x_1 + \ldots + \beta_nx_n}}
\end{aligned}`
$$

---

layout: true

# "The" effect is nonlinear in _p_

$$
`\begin{aligned}
p &amp; = \frac{e^{\beta_0 + \beta_1x_1 + \ldots + \beta_nx_n}}{1 + e^{\beta_0 + \beta_1x_1 + \ldots + \beta_nx_n}}
\end{aligned}`
$$

---

--

&lt;img src="Powerpoint_presentation_files/figure-html/unnamed-chunk-2-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

&lt;img src="Powerpoint_presentation_files/figure-html/unnamed-chunk-3-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

&lt;img src="Powerpoint_presentation_files/figure-html/unnamed-chunk-4-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

layout: false

class: inverse, center, middle

# Sample dataset and model

---

# Datset



- Our simulated dataset describes students who took Balloon Animal-Making 201 at University Imaginary

--

&lt;table class="table table-striped table-hover" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Variable &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Possible Responses &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Variable Type &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Mac user &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE/FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; binary &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Wear glasses &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE/FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; binary &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Pet type &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog, cat, fish, none &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; categorical &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Favorite color &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; blue, red, green, orange &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; categorical &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Prior undergraduate GPA &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.0-4.0 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; continuous &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Height &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 54-77 inches &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; continuous &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Went to tutoring &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE/FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; binary &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Passed &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE/FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; binary &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Dataset


```r
library(tidyverse)
df = read.csv("data/course_outcomes.csv", header = T, stringsAsFactors = F)
```

&lt;table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; id &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; mac &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; glasses &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; pet.type &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; favorite.color &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; prior.gpa &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; height &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; tutoring &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; passed &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.86 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cat &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; green &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 66 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; none &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; orange &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.98 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 66 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.78 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cat &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; blue &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.73 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 67 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; green &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.99 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; none &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.75 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.73 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; none &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 64 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; orange &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.64 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 11 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dog &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.98 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cat &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; green &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 64 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Model

- Dependent variable: did the student pass?

--

- Continuous variables were centered and standardized


```r
df = df %&gt;%
  mutate(
    cs.prior.gpa = (prior.gpa - mean(prior.gpa)) / sd(prior.gpa),
    cs.height = (height - mean(height)) / sd(height)
  )
```

--

- Reference levels for categorical variables:

  - Pet type: none

  - Favorite color: blue


```r
df = df %&gt;%
  mutate(
    pet.type = fct_relevel(pet.type, "none", "dog", "cat", "fish"),
    favorite.color = fct_relevel(favorite.color, "blue", "red",
                                 "green", "orange")
  )
```

---

# Model


```r
library(lme4)
pass.m = glm(passed ~ mac + glasses + pet.type + favorite.color + cs.prior.gpa +
               cs.height + tutoring,
             data = df, family = binomial(link = "logit"))
summary(pass.m)$coefficients
```

```
##                         Estimate Std. Error    z value      Pr(&gt;|z|)
## (Intercept)           1.53678432 0.09665694 15.8993682  6.400698e-57
## macTRUE              -0.04070026 0.08251424 -0.4932514  6.218350e-01
## glassesTRUE           0.19330654 0.07787099  2.4823948  1.305026e-02
## pet.typedog          -0.25143138 0.08483778 -2.9636722  3.039919e-03
## pet.typecat           0.09616174 0.11927784  0.8061995  4.201278e-01
## pet.typefish         -1.19359401 0.16656361 -7.1659949  7.722363e-13
## favorite.colorred    -0.03945396 0.09265674 -0.4258078  6.702479e-01
## favorite.colorgreen  -0.38137532 0.10062190 -3.7901819  1.505370e-04
## favorite.colororange -0.24204783 0.13900517 -1.7412865  8.163337e-02
## cs.prior.gpa          1.03092175 0.03887172 26.5211237 5.531945e-155
## cs.height            -0.25908893 0.03833829 -6.7579681  1.399404e-11
## tutoringTRUE          0.22698497 0.07583279  2.9932300  2.760416e-03
```

---

# Model


```r
library(lme4)
pass.m = glm(passed ~ mac + glasses + pet.type + favorite.color + cs.prior.gpa +
               cs.height + tutoring,
             data = df, family = binomial(link = "logit"))
summary(pass.m)$coefficients
```

```
##                         Estimate Std. Error    z value      Pr(&gt;|z|)
## (Intercept)           1.53678432 0.09665694 15.8993682  6.400698e-57
## macTRUE              -0.04070026 0.08251424 -0.4932514  6.218350e-01
*## glassesTRUE           0.19330654 0.07787099  2.4823948  1.305026e-02
*## pet.typedog          -0.25143138 0.08483778 -2.9636722  3.039919e-03
## pet.typecat           0.09616174 0.11927784  0.8061995  4.201278e-01
*## pet.typefish         -1.19359401 0.16656361 -7.1659949  7.722363e-13
## favorite.colorred    -0.03945396 0.09265674 -0.4258078  6.702479e-01
*## favorite.colorgreen  -0.38137532 0.10062190 -3.7901819  1.505370e-04
## favorite.colororange -0.24204783 0.13900517 -1.7412865  8.163337e-02
*## cs.prior.gpa          1.03092175 0.03887172 26.5211237 5.531945e-155
*## cs.height            -0.25908893 0.03833829 -6.7579681  1.399404e-11
*## tutoringTRUE          0.22698497 0.07583279  2.9932300  2.760416e-03
```

---

# Causality disclaimer

- Some visualizations strongly imply a causal interpretation

--

- It's your responsibility to evaluate whether a causal interpretation is appropriate

--

- If the data doesn't support a causal interpretation, **don't use a visualization that implies one**

---

class: inverse, center, middle
# Visualitization Option 1: 
# Presenting Model Coefficients

---

# Presenting model coefficients



&lt;table class="table table-striped table-hover" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parameter &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Standard error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Intercept &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.5367843 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0966569 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.8993682 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0000000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Mac &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.0407003 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0825142 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.4932514 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.6218350 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Glasses &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1933065 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0778710 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.4823948 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0130503 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Pet: Dog &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.2514314 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0848378 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.9636722 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0030399 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Pet: Cat &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0961617 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1192778 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.8061995 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.4201278 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Pet: Fish &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.1935940 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1665636 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -7.1659949 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0000000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Favorite color: Red &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.0394540 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0926567 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.4258078 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.6702479 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Favorite color: Green &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.3813753 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1006219 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.7901819 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0001505 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Favorite color: Orange &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.2420478 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1390052 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.7412865 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0816334 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Prior GPA
(0.6-pt increase) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.0309217 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0388717 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 26.5211237 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0000000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Height
(3-in increase) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.2590889 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0383383 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -6.7579681 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0000000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Tutoring &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2269850 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0758328 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.9932300 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0027604 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Change in the log-odds






&lt;img src="Powerpoint_presentation_files/figure-html/change-in-log-odds-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Change in the log-odds

### Pros

--

- Catalogs which effects are positive, negative, or no effect through the use of **color** and **order**

--

- The numerical values are in one place: the x-axis

--

### Cons

--

- The magnitude of effect is in the log-odds scale

--

  - what is a 0.4 change in the log-odds?
  
--

  - is the change between 0.4 and 0.8 log-odds "big" or "small"?

---

# Secret Log-Odds

&lt;img src="Powerpoint_presentation_files/figure-html/change-in-log-odds-adjusted-axis-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Secret Log-Odds

.pull-left[
&lt;img src="Powerpoint_presentation_files/figure-html/change-in-log-odds-adjusted-axis-1.png" width="504" /&gt;
]

.pull-right[
- It's a simple adjustment, just relabels the x-axis
- No unit of measurement to describe their absolute effect size
- Still will not get a sense of the overall magnitude of effect
]

---

#  Change in odds ratio

Your audience may be more familiar with the "odds" part of log-odds

--

$$
`\begin{aligned}
\log\left(\begin{array}{c}\frac{p}{1 - p}\end{array}\right) &amp; = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n \\&amp;\\
\frac{p}{1 - p} &amp; = e^{\beta_0 + \beta_1x_1 + \ldots + \beta_nx_n}
\end{aligned}`
$$

---

# Change in odds ratio


&lt;img src="Powerpoint_presentation_files/figure-html/odds-ratio-adjusted-axis-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Change in odds ratio

--

## Pros

- Changes in odds might be easier to describe than changes in log-odds

--

## Cons
--

- Two non-trivial obstacles:

--

  1. Odds are expressed as integer ratios ("3-to-1" or "2-to-5") rather than "3" or "0.4‚Äù
  
--

  2. Coefficients of your model don't represent odds directly; they represent the *changes* in odds
  
--

- The percent change in log odds might be misinterpreted as the absolute probability of the outcome (or the change in its probability)

---

class: inverse, center, middle
# Visualization Option 2
# Presenting probabilities

---

# Probabilities relative to some baseline

--

-  Problem with presenting probabilities with logistic regression: the change in percentage points depends on the baseline starting value

--

- We can choose an appropriate baseline probability 

--

- One option for the baseline is to use the overall intercept of the model 

---

# Probabilities relative to some baseline



&lt;img src="Powerpoint_presentation_files/figure-html/probability-relative-to-some-baseline-no-arrows-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Probabilities relative to some baseline


&lt;img src="Powerpoint_presentation_files/figure-html/probability-relative-to-some-baseline-with-arrows-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Probabilities relative to some baseline

--

## Pros

--

- Uses a scale that your audience is already very familiar with: probabilities (expressed as percentages)

--

- Avoids a common, but misleading, way of presenting changes in probabilities: the "percent change" formulation

---

# Probabilities relative to some baseline

--

## Cons

--

- Have to choose a baseline

--

- Representing an "average" student seems reasonable, but the process for doing so depends on how the model is specified:

--

  - the intercept represents a student with average values for the continuous predictors because we standardized those predictors
  
--

  - with respect to the categorical predictors, our baseline represents a student who is _not_ actually all that average: it's a student who is not a Mac user, doesn't wear glasses, etc. All of our baseline categories are the most frequent values in the dataset


---

# Multiple baselines by group

--

Instead of choosing one baseline we can choose several baselines

---

# Multiple baselines by group

--



&lt;img src="Powerpoint_presentation_files/figure-html/probability-relative-to-some-baseline-and-group-no-arrows-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Multiple baselines by group

&lt;img src="Powerpoint_presentation_files/figure-html/probability-relative-to-some-baseline-and-group-with-arrows-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Multiple baselines by group

--

## Pros

--

- Emphasizes that the baseline we show is a _choice_, and that different students have different baselines

--

- Explicitly shows how the effect of a given predictor varies depending on the baseline

--

- Show different effects by group

--

   - In our example, the larger effect for students with fish is purely a function of their lower baseline

--

  - Imagine a model with true _interactions_ between pet type and other predictors

---

# Multiple baselinse by group

-- 

## Cons

--

- Still have to _choose_ a baseline


--

- More cluttered than a single graph

---

# Banana graphs

--

- We can overcome this baseline picking-and-choosing problem by iterating across every baseline.

--

- For example:

--

  - we can calculate the 0% to 100% predicted probability of passing Balloon Animal-Making 201 for a student who does not own a pet fish.
  
--

  - use those baseline values to compute the predicted probability of a student who does own a pet fish
  
---

# Banana graphs





&lt;img src="Powerpoint_presentation_files/figure-html/banana-graph-bare-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Banana graphs

- **x axis** values for each point on the curve is the baseline probability, i.e., the probability that the student does not own a pet fish

--

- **y axis** values for each point on the curve is the probability increase or decrease from the baseline, i.e., the probability that the student does own a pet fish

--

- **solid line** which goes diagonally across the middle of the graph as a reference line: 

--

  - **Above the solid line**: the predictor variable has a higher predicted probability of passing than its baseline
  
--
  - **On the solid line**: the predictor variable has the same predicted probability of passing as its baseline
  
--

  - **Below the solid line**: the predictor variable has a lower predicted probability of passing than its baseline


---

# Banana graphs

&lt;img src="Powerpoint_presentation_files/figure-html/banana-graph-annotated-1.png" width="648" style="display: block; margin: auto;" /&gt;

---

# Banana graphs

&lt;img src="Powerpoint_presentation_files/figure-html/banana-graph-multiple-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Banana graphs

--

## Pros

--

- Do not have to pick and choose a baseline &amp;rarr; show the whole range of predicted probabilities

--

## Cons

- Can take up quite a bit of space

--

- Audience's eyes have to dart from one graph to the next to compare any two predictor variables

--

- Initially it could be difficult to understand

---

class: inverse, center, middle
# Visualization Option 3
# Presenting counterfactual counts

---

# Presenting counterfactual counts

--

- Sometimes stakeholders are interested in a measure that's even more basic than probabilities: **the number of times something happens (or doesn't happen)**

--

- Example: suppose your stakeholders want to use your analysis to assess the impact of tutoring on pass rates in Balloon Animal-Making 201

--

  - They're interested not just in _whether_ tutoring helps students, but _how much_ it helps them.
  

---

# Extra successes

## The idea

--

In our dataset, 2,571 students received tutoring; of those, 2,023 passed the class. 

--

Suppose those students had _not_ received tutoring; in that case, how many students do we think would have passed? 

--

In other words, how many "extra" passes did we get because of tutoring?

---

# Extra successes

## The approach

--

We can get a simple point estimate by using our model to predict outcomes for the subset of our data where students received tutoring, but with the `tutoring` predictor set to `FALSE` instead of `TRUE` -- in other words, by running a set of counterfactual predictions. 

--

A point estimate doesn't convey the amount of uncertainty around our estimate; we can get confidence intervals by simulating many sets of outcomes and aggregating over them.

---

# Extra successes



&lt;img src="Powerpoint_presentation_files/figure-html/extra-passes-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Extra successes

--

## Pros

--

- This approach is clear and straightforward if your stakeholders care about the magnitude of an effect in terms of counts

--

## Cons

--

- It strongly implies a causal relationship between the predictor and the outcome: we're claiming that the tutoring _caused_ some students to pass who otherwise wouldn't have

--

- Assumes that the counterfactual makes sense

--

- Using a histogram to summarize the simulations: audience might be distracted by the whole idea of using simulation to estimate uncertainty

---

# Extra successes by group

We can summarize counterfactuals by group for a more fine-grained view of our model's predictions
 
---

# Extra successes by group

&lt;img src="Powerpoint_presentation_files/figure-html/extra-passes-by-group-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Extra successes by group

--

## Pros

--

-  Avoids a scale that shows the number of simulations, and instead focuses on the range of predictions 

--

- Shows how the effect varies by group

--

## Pro/Con

--

Recall, tutoring gives a larger percentage point boost to students with fish, because those students started out with a lower baseline probability of passing. 

--

But this graph shows that the absolute _number_ of extra passing students with fish is _smaller_ than for other groups; this is because there simply aren't that many students with fish in the first place.

---

# Potential successes compared to group size

--

- Attempt to show _both_ the effect size for each group _and_ the overall size of that group

--

- Switch the direction of the counterfactual: instead of predicting how many tutored students passed who otherwise wouldn't have, we're going to predict how many _untutored_ students _would have_ passed if they had received tutoring

---

# Potential successes compared to group size

&lt;img src="Powerpoint_presentation_files/figure-html/potential-passes-by-group-1.png" width="504" style="display: block; margin: auto;" /&gt;

---

# Potential successes compared to group size

--

## Pro

- Step towards acknowledging different group sizes, and it also helps put the absolute numbers in context

--

## Cons

--

- Makes a strong causal claim, which may not be appropriate for your model

--

- Doesn't convey the size of the _whole_ group, only of the number of passing students in the group 

--

- If you have groups of vastly unequal sizes, then the effects for smaller groups will be squashed at the bottom of the scale and difficult to see

---

# Concluding Remarks

--

- There is no right or wrong way, only better and worse ways, so, get creative! 

--

- Knowing your stakeholders as well as the context and purpose of your research should be your guides to determine which visualization is most appropriate

--

- Use colors, the layout, and annotations to your advantage

--

- Share your ideas with others

---

class: inverse, center, middle
# Thank you


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
